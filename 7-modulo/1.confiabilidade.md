# Como criar visando a confiabilidade

Depois das principais métricas de desempenho, nosso tema é a confiabilidade. Replique os dados e crie várias instâncias de máquina virtual para evitar pontos únicos de falha. Definir a unidade de desenvolvimento e entender os recursos dela é essencial. Para evitar pontos únicos de falha, implante duas instâncias extras, ou N+2, para lidar com falhas e upgrades. Procure implantar as instâncias em zonas diferentes para não ter problemas com falhas zonais.

Mas vamos falar sobre upgrades. Imagine que a carga de três VMs é balanceada para alcançar N+2. Se uma delas está fazendo upgrade e a outra falha, 50% da capacidade de computação disponível é removida. A carga da outra instância pode dobrar, e as chances de falha aumentam. Por isso, é importante planejar a capacidade e saber os limites da sua unidade de implantação. E para facilitar o escalonamento, transforme as unidades de implantação em clones sem estado intercambiáveis.

Também é importante saber o que são falhas correlacionadas. Elas acontecem quando itens relacionados falham ao mesmo tempo. Basicamente, se uma única máquina falha, as solicitações atendidas por ela falham. Em um hardware, se um interruptor da parte superior do rack falha, o rack inteiro falha. Na nuvem, se uma zona ou região é perdida, todos os recursos ficam indisponíveis. Isso acontece com servidores em execução no mesmo software. Se um software falha, os servidores podem falhar quase ao mesmo tempo. Dados de configuração também podem sofrer falhas correlacionadas. Se um sistema de configuração global falha, e vários sistemas dependem dele, eles também podem falhar. Chamamos um grupo de itens relacionados que podem falhar juntos de domínio de falha.

Existem diversas técnicas para evitar falhas correlacionadas. É importante identificar os domínios de falha. Assim os servidores podem ser separados usando microsserviços distribuídos por vários desses domínios. Para isso, divida a lógica de negócios em serviços com base em domínios de falha e faça a implantação em várias zonas ou regiões. Em um nível maior de granularidade, é interessante dividir as responsabilidades entre componentes e distribuir por vários processos. Assim, quando um componente falha, os outros não são afetados. Se todas as responsabilidades estão em um componente, é possível que todos os componentes falhem quando uma responsabilidade falhar.

Ao projetar microsserviços, desenvolva serviços acoplados com flexibilidade e independentes, mas colaborativos. A falha de um serviço não provoca a falha dos outros. Quando isso acontece, os serviços colaborativos têm a capacidade reduzida ou não processam totalmente os fluxos de trabalho. Mas o serviço colaborativo permanece no controle e não falha. Falhas em cascata acontecem quando um sistema falha, e os outros ficam sobrecarregados e acabam falhando também. Por exemplo, uma fila de mensagens pode estar sobrecarregada devido à falha de um back-end e não consegue processar mensagens em espera.

Então como evitar esse tipo de falha? Use o suporte da plataforma de implantação para corrigir falhas em cascata. No Compute Engine, é possível usar verificações de integridade. E o GKE oferece sondagens de prontidão e ativação para detectar e corrigir instâncias não íntegras. É importante garantir a rápida inicialização de novas instâncias e que outros sistemas ou back-ends não as iniciem antes de estarem prontas.

Planeje também ações contra as _queries of death_: consultas a um serviço que provocam a falha dele. Esse tipo de consulta leva esse nome porque se manifesta como um consumo excessivo de recursos, mas acontece devido a um erro na lógica de negócios. O diagnóstico pode ser difícil e exige bom monitoramento, observabilidade e geração de registros para determinar a causa principal do problema. Ao receber uma solicitação, é preciso monitorar a latência, os recursos, o uso e as taxas de erro para identificar o problema.

Planeje ações contra falhas de sobrecarga do ciclo de feedback positivo quando um problema surgir ao tentar evitar problemas. Isso acontece quando você faz novas tentativas em um evento de falha para que o sistema fique mais confiável. Em vez de corrigir a falha, isso pode gerar sobrecarga. Na verdade, você aumenta a sobrecarga de um sistema já sobrecarregado. A solução é fazer novas tentativas inteligentes com o feedback do serviço que está falhando.

Vamos ver duas estratégias para resolver esse problema. Se um serviço falha, podemos fazer novas tentativas. O importante é que elas sejam controladas. Uma opção é usar o padrão de espera exponencial. Ele executa uma nova tentativa não imediata. É preciso esperar para fazer a nova tentativa, e quando há falha, o tempo de espera aumenta um pouco. Assim o serviço com falha tem tempo para se recuperar. É importante limitar o número de novas tentativas, bem como o tempo para desistir. Imagine que uma solicitação a um serviço falhou. Podemos usar a espera exponencial e esperar um segundo e alguns milissegundos para tentar novamente. Se a solicitação falhar novamente, esperamos dois segundos e alguns milissegundos para tentar novamente. Falhou novamente? Mais quatro minutos de espera e alguns milissegundos para tentar novamente e continuamos até alcançar o limite.

O padrão de disjuntor também protege o serviço de muitas tentativas. Ele implementa uma solução que atua quando o estado de operação do serviço está degradado. Isso é útil porque, se o serviço está inativo ou sobrecarregado e os clientes fazem novas tentativas, as solicitações extras pioram a situação. O padrão de design do disjuntor protege o serviço por trás de um proxy que monitora a integridade. Se o serviço não é considerado íntegro pelo disjuntor, as solicitações não são encaminhadas. Quando o serviço volta a ficar operacional, o disjuntor volta a enviar solicitações, mas de forma controlada. Se você está usando o GKE, a malha de serviço do Istio implementa o disjuntor automaticamente.

A exclusão lenta é um método baseado na capacidade de recuperação confiável dos dados quando um usuário os exclui por engano. Nesse método, você inicia um pipeline de exclusão e a exclusão segue em fases. No primeiro estágio, o usuário exclui os dados, que podem ser recuperados em um período definido, por exemplo, são 30 dias. Isso protege o usuário contra erros. Quando o período definido chega ao fim, o usuário não pode mais ver os dados, porque estão na fase de exclusão lenta. Agora o suporte ao cliente ou administradores podem recuperar os dados. Essa fase protege contra erros no aplicativo. Depois do período de exclusão lenta de 15, 30, 45 ou até 50 dias, os dados são excluídos e ficam indisponíveis. Quando isso acontece, só é possível recuperar os dados por backup ou arquivos.