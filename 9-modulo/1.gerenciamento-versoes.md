# Gerenciamento de versões

Vamos começar analisando o gerenciamento de versões. Uma vantagem essencial da arquitetura de microsserviços é a capacidade de implantá-los de forma independente. Isso significa que a API de serviço precisa ser protegida. É preciso fazer controle de versões e, ao implantar novas versões, você precisa tomar medidas para garantir compatibilidade com uma versão anterior. Algumas regras simples de design podem ajudar, como indicar a versão no URI e garantir que ela seja alterada ao fazer uma mudança incompatível com versões anteriores. Implantar novas versões de software sempre representa um risco. Precisamos testar as novas versões antes da publicação. Quando tudo estiver pronto para implantar a nova versão, vamos fazer isso sem inatividade alguma. Vamos discutir algumas estratégias que podem ser úteis. As atualizações graduais ajudam a implantar novas versões sem inatividade. Normalmente, a configuração tem várias instâncias de um servidor por trás de um balanceador de carga. A atualização gradual modifica uma instância por vez. Essa estratégia funciona quando a API não é alterada, quando ela é compatível com versões anteriores ou quando não há problemas em ter duas versões do mesmo serviço durante a atualização. Se você usa grupos de instâncias, as atualizações contínuas são um recurso integrado. A estratégia de atualização gradual só é definida quando você faz a atualização. No Kubernetes, as atualizações graduais são ativadas por padrão. Você só precisa especificar a imagem de substituição do Docker. No App Engine, as atualizações graduais são totalmente automatizadas. 

Use uma implantação azul/verde caso não queira que várias versões de um serviço operem simultaneamente. Essas implantações usam dois ambientes completos. A implantação azul executa o software atual de produção implantada. Já o ambiente de implantação verde está disponível para implantar versões atualizadas do software. Quando quiser testar uma nova versão do software, implante no ambiente verde. Quando o teste for concluído, a carga de trabalho será movida do ambiente atual, ou azul, nesse caso, para o novo ambiente verde. Essa estratégia reduz o risco de implantações incorretas, permitindo voltar à implantação anterior se algo der errado. 

No Compute Engine, é possível usar DNS para solicitações de migração. Já no Kubernetes, você pode configurar o serviço para encaminhar a novos pods usando identificadores, que são mudanças simples de configuração. Com o App Engine, é possível dividir o tráfego. Você pode usar versões canário antes de uma atualização gradual para reduzir o risco. Com uma versão canário, você faz a nova implantação enquanto a atual ainda está em execução. Depois você envia uma pequena porcentagem do tráfego à nova implantação e a monitora. Quando tiver confiança na nova implantação, encaminhe mais tráfego a ela, até que 100% do processo tenha sido enviado assim. No Compute Engine, é possível criar um novo grupo de instâncias e adicioná-lo ao balanceador de carga como um back-end extra. No Kubernetes, você pode criar um novo pod com os mesmos identificadores dos pods atuais. O serviço vai direcionar automaticamente uma parte das solicitações ao novo pod. No App Engine, é possível usar novamente um recurso de divisão de tráfego para encaminhar parte do tráfego à nova versão.